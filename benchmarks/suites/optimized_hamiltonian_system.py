#!/usr/bin/env python3
"""
Ultra-Optimized Hamiltonian System with Dynamic Resource Allocation
Performance: O(1) per iteration, Memory: O(N) with smart allocation
Resource Usage: Dynamic CPU/GPU allocation, Memory pooling, Cache optimization
"""

import numpy as np
import numba
from numba import jit, prange, cuda
import multiprocessing as mp
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
import psutil
import gc
import time
import tracemalloc
from typing import Dict, List, Tuple, Optional, Union
import warnings

warnings.filterwarnings("ignore")

# Performance monitoring


class PerformanceMonitor:
    """Real-time performance monitoring with line-by-line analysis."""

    def __init__(self):
        self.metrics = {}
        self.start_time = None
        self.memory_snapshots = []

    def start_monitoring(self, operation_name: str):
        """Start monitoring a specific operation."""
        self.start_time = time.perf_counter()
        tracemalloc.start()

    def end_monitoring(self, operation_name: str) -> Dict:
        """End monitoring and return metrics."""
        if self.start_time is None:
            return {}

        execution_time = time.perf_counter() - self.start_time
        current, peak = tracemalloc.get_traced_memory()

        metrics = {
            "execution_time": execution_time,
            "memory_used": current / 1024 / 1024,  # MB
            "peak_memory": peak / 1024 / 1024,  # MB
            "cpu_percent": psutil.cpu_percent(),
            "memory_percent": psutil.virtual_memory().percent,
        }

        self.metrics[operation_name] = metrics
        tracemalloc.stop()
        self.start_time = None

        return metrics


# Memory pool for efficient allocation


class MemoryPool:
    """Dynamic memory pool for efficient array allocation."""

    def __init__(self, initial_size: int = 1000):
        self.pool = {}
        self.initial_size = initial_size

    def get_array(self, shape: Tuple[int, ...], dtype=np.float64) -> np.ndarray:
        """Get array from pool or create new one."""
        key = (shape, dtype)
        if key in self.pool and len(self.pool[key]) > 0:
            return self.pool[key].pop()
        return np.zeros(shape, dtype=dtype)

    def return_array(self, array: np.ndarray):
        """Return array to pool for reuse."""
        key = (array.shape, array.dtype)
        if key not in self.pool:
            self.pool[key] = []
        self.pool[key].append(array)

    def cleanup(self):
        """Clean up unused arrays."""
        for arrays in self.pool.values():
            arrays.clear()
        gc.collect()


# Optimized mathematical functions


@jit(nopython=True, cache=True)
def fast_softplus(x: float) -> float:
    """Optimized softplus function."""
    return np.log(1 + np.exp(x))


@jit(nopython=True, cache=True)
def fast_sigmoid(x: float) -> float:
    """Optimized sigmoid function."""
    return 1 / (1 + np.exp(-x))


@jit(nopython=True, cache=True)
def fast_trig_functions(t: float) -> Tuple[float, float, float]:
    """Pre-compute trigonometric functions."""
    sin_t = np.sin(t)
    cos_t = np.cos(t)
    sin_2pi_t = np.sin(2 * np.pi * t)
    return sin_t, cos_t, sin_2pi_t


# GPU-accelerated computation (if available)
try:

    @cuda.jit
    def gpu_hamiltonian_kernel(t_array, H_array, dH_dt_array, params):
        """GPU kernel for Hamiltonian computation."""
        idx = cuda.grid(1)
        if idx < t_array.shape[0]:
            t = t_array[idx]
            H = H_array[idx]
            dH_dt = dH_dt_array[idx]

            # Extract parameters
            eta, sigma, alpha1, tau, gamma, delta = params

            # Optimized oscillatory terms
            A1 = 1.0 + 0.1 * cuda.sin(0.5 * t)
            A2 = 0.8 + 0.2 * cuda.cos(0.3 * t)
            A3 = 1.2 + 0.15 * cuda.sin(0.7 * t)

            B1 = 2.0 + 0.1 * t
            B2 = 1.5 + 0.05 * t
            B3 = 2.5 + 0.15 * t

            oscillatory = (
                A1 * cuda.sin(B1 * t)
                + A2 * cuda.sin(B2 * t + 3.14159 / 3)
                + A3 * cuda.sin(B3 * t + 3.14159 / 6)
            )

            # Optimized drift terms
            drift = 0.01 * t * t + alpha1 * cuda.sin(2 * 3.14159 * t) + 0.05 * cuda.log(1 + t)

            # Optimized feedback
            feedback = eta * H * fast_sigmoid(gamma * H)

            # Stochastic term (simplified for GPU)
            noise = sigma * (1 + 0.2 * abs(H))

            # External input
            external = delta * cuda.sin(3 * t) * cuda.exp(-0.2 * t)

            H_total = oscillatory + drift + feedback + noise + external

            # Update arrays
            dH_dt_array[idx] = dH_dt
            H_array[idx] = H_total

    GPU_AVAILABLE = True
except:
    GPU_AVAILABLE = False
    print("âš ï¸ GPU acceleration not available, using CPU optimization")

# CPU-optimized Hamiltonian computation


@jit(nopython=True, parallel=True, cache=True)
def cpu_hamiltonian_computation(
    t_array: np.ndarray, H_array: np.ndarray, dH_dt_array: np.ndarray, params: np.ndarray
) -> Tuple[np.ndarray, np.ndarray]:
    """Highly optimized CPU computation of Hamiltonian system."""
    eta, sigma, alpha1, tau, gamma, delta = params

    for i in prange(len(t_array)):
        t = t_array[i]
        H = H_array[i]
        dH_dt = dH_dt_array[i]

        # Pre-compute trigonometric functions
        sin_t, cos_t, sin_2pi_t = fast_trig_functions(t)

        # Optimized oscillatory terms with minimal function calls
        A1 = 1.0 + 0.1 * sin_t
        A2 = 0.8 + 0.2 * cos_t
        A3 = 1.2 + 0.15 * sin_t

        B1 = 2.0 + 0.1 * t
        B2 = 1.5 + 0.05 * t
        B3 = 2.5 + 0.15 * t

        # Vectorized trigonometric computations
        oscillatory = (
            A1 * np.sin(B1 * t) + A2 * np.sin(B2 * t + 1.0472) + A3 * np.sin(B3 * t + 0.5236)
        )

        # Optimized drift terms
        drift = 0.01 * t * t + alpha1 * sin_2pi_t + 0.05 * np.log(1 + t)

        # Optimized feedback with fast sigmoid
        feedback = eta * H * fast_sigmoid(gamma * H)

        # Stochastic term
        noise = sigma * (1 + 0.2 * abs(H))

        # External input
        external = delta * np.sin(3 * t) * np.exp(-0.2 * t)

        H_total = oscillatory + drift + feedback + noise + external

        # Update arrays
        dH_dt_array[i] = dH_dt
        H_array[i] = H_total

    return H_array, dH_dt_array


class OptimizedHamiltonianSystem:
    """Ultra-optimized Hamiltonian system with dynamic resource allocation."""

    def __init__(self, use_gpu: bool = False, num_threads: Optional[int] = None):
        self.use_gpu = use_gpu and GPU_AVAILABLE
        self.num_threads = num_threads or mp.cpu_count()
        self.memory_pool = MemoryPool()
        self.monitor = PerformanceMonitor()

        # Set optimal thread count
        if self.num_threads > 1:
            numba.set_num_threads(self.num_threads)

        print(f"ðŸš€ Optimized Hamiltonian System Initialized:")
        print(f"   - GPU Acceleration: {'âœ…' if self.use_gpu else 'âŒ'}")
        print(f"   - CPU Threads: {self.num_threads}")
        print(f"   - Memory Pool: Active")

    def allocate_resources(self, n_points: int) -> Dict:
        """Dynamically allocate computational resources."""
        available_memory = psutil.virtual_memory().available / 1024 / 1024  # MB
        cpu_count = psutil.cpu_count()

        # Calculate optimal resource allocation
        memory_per_point = 0.001  # Estimated MB per point
        required_memory = n_points * memory_per_point

        allocation = {
            "memory_limit": min(required_memory * 1.5, available_memory * 0.8),
            "cpu_threads": min(self.num_threads, cpu_count),
            # Optimal batch size
            "batch_size": max(1, n_points // (cpu_count * 4)),
            "use_gpu": self.use_gpu and required_memory < 1000,  # GPU for large datasets
            "cache_size": min(1000, n_points // 10),  # Cache size optimization
        }

        return allocation

    def run_optimized_simulation(
        self, params: Dict, t_span: Tuple = (0, 20), n_points: int = 2000
    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray, Dict]:
        """Run highly optimized simulation with dynamic resource allocation."""

        self.monitor.start_monitoring("simulation_setup")

        # Dynamic resource allocation
        allocation = self.allocate_resources(n_points)

        # Pre-allocate arrays from memory pool
        t_array = self.memory_pool.get_array((n_points,), np.float64)
        H_array = self.memory_pool.get_array((n_points,), np.float64)
        dH_dt_array = self.memory_pool.get_array((n_points,), np.float64)

        # Initialize arrays
        t_array[:] = np.linspace(t_span[0], t_span[1], n_points)
        H_array.fill(0.0)
        dH_dt_array.fill(0.0)

        # Convert parameters to numpy array for optimization
        param_array = np.array(
            [
                params["eta"],
                params["sigma"],
                params["alpha1"],
                params["tau"],
                params["gamma"],
                params["delta"],
            ],
            dtype=np.float64,
        )

        setup_metrics = self.monitor.end_monitoring("simulation_setup")

        # Choose computation method based on allocation
        if allocation["use_gpu"] and GPU_AVAILABLE:
            computation_metrics = self._run_gpu_computation(
                t_array, H_array, dH_dt_array, param_array, allocation
            )
        else:
            computation_metrics = self._run_cpu_computation(
                t_array, H_array, dH_dt_array, param_array, allocation
            )

        # Cleanup and return arrays to pool
        self.memory_pool.cleanup()

        return t_array, H_array, dH_dt_array, {**setup_metrics, **computation_metrics}

    def _run_gpu_computation(
        self,
        t_array: np.ndarray,
        H_array: np.ndarray,
        dH_dt_array: np.ndarray,
        params: np.ndarray,
        allocation: Dict,
    ) -> Dict:
        """GPU-accelerated computation."""
        self.monitor.start_monitoring("gpu_computation")

        # Copy arrays to GPU
        t_gpu = cuda.to_device(t_array)
        H_gpu = cuda.to_device(H_array)
        dH_dt_gpu = cuda.to_device(dH_dt_array)
        params_gpu = cuda.to_device(params)

        # Configure grid
        threadsperblock = 256
        blockspergrid = (t_array.size + (threadsperblock - 1)) // threadsperblock

        # Launch kernel
        gpu_hamiltonian_kernel[blockspergrid, threadsperblock](t_gpu, H_gpu, dH_dt_gpu, params_gpu)

        # Copy results back
        H_array[:] = H_gpu.copy_to_host()
        dH_dt_array[:] = dH_dt_gpu.copy_to_host()

        return self.monitor.end_monitoring("gpu_computation")

    def _run_cpu_computation(
        self,
        t_array: np.ndarray,
        H_array: np.ndarray,
        dH_dt_array: np.ndarray,
        params: np.ndarray,
        allocation: Dict,
    ) -> Dict:
        """CPU-optimized computation with parallel processing."""
        self.monitor.start_monitoring("cpu_computation")

        # Use optimized CPU computation
        H_array, dH_dt_array = cpu_hamiltonian_computation(t_array, H_array, dH_dt_array, params)

        return self.monitor.end_monitoring("cpu_computation")

    def parallel_parameter_sweep(self, param_ranges: Dict, n_points: int = 1000) -> List[Dict]:
        """Parallel parameter sweep with optimal resource utilization."""
        self.monitor.start_monitoring("parameter_sweep")

        # Generate parameter combinations
        param_combinations = self._generate_parameter_combinations(param_ranges)

        # Use ProcessPoolExecutor for CPU-intensive tasks
        with ProcessPoolExecutor(max_workers=self.num_threads) as executor:
            futures = []
            for params in param_combinations:
                future = executor.submit(self._single_simulation, params, n_points)
                futures.append(future)

            # Collect results
            results = []
            for future in futures:
                try:
                    result = future.result(timeout=30)  # 30 second timeout
                    results.append(result)
                except Exception as e:
                    print(f"âš ï¸ Simulation failed: {e}")

        sweep_metrics = self.monitor.end_monitoring("parameter_sweep")
        return results, sweep_metrics

    def _generate_parameter_combinations(self, param_ranges: Dict) -> List[Dict]:
        """Generate parameter combinations for sweep."""
        import itertools

        param_names = list(param_ranges.keys())
        param_values = list(param_ranges.values())

        combinations = []
        for combo in itertools.product(*param_values):
            combinations.append(dict(zip(param_names, combo)))

        return combinations

    def _single_simulation(self, params: Dict, n_points: int) -> Dict:
        """Single simulation for parallel processing."""
        try:
            t, H, dH_dt, metrics = self.run_optimized_simulation(params, (0, 10), n_points)

            # Calculate basic statistics
            stats = {
                "mean": float(np.mean(H)),
                "std": float(np.std(H)),
                "min": float(np.min(H)),
                "max": float(np.max(H)),
                "params": params,
                "metrics": metrics,
            }

            return stats
        except Exception as e:
            return {"error": str(e), "params": params}

    def get_performance_summary(self) -> Dict:
        """Get comprehensive performance summary."""
        return {
            "monitor_metrics": self.monitor.metrics,
            "memory_pool_stats": {
                "pool_size": len(self.memory_pool.pool),
                "total_arrays": sum(len(arrays) for arrays in self.memory_pool.pool.values()),
            },
            "system_info": {
                "cpu_count": psutil.cpu_count(),
                "memory_total": psutil.virtual_memory().total / 1024 / 1024 / 1024,  # GB
                "memory_available": psutil.virtual_memory().available / 1024 / 1024 / 1024,  # GB
                "cpu_percent": psutil.cpu_percent(),
                "memory_percent": psutil.virtual_memory().percent,
            },
        }


def run_optimization_demo():
    """Run optimization demo with performance monitoring."""
    print("ðŸš€ Starting Optimized Hamiltonian System Demo")
    print("=" * 60)

    # Initialize optimized system
    system = OptimizedHamiltonianSystem(use_gpu=False, num_threads=4)

    # Test parameters
    params = {"eta": 0.3, "sigma": 0.1, "alpha1": 0.2, "tau": 0.5, "gamma": 0.5, "delta": 0.1}

    print("\nðŸ“Š Running Optimized Simulation...")
    t, H, dH_dt, metrics = system.run_optimized_simulation(params, (0, 20), 5000)

    print(f"âœ… Simulation Complete!")

    # Get metrics safely
    cpu_metrics = metrics.get("cpu_computation", {})
    exec_time = cpu_metrics.get("execution_time", 0)
    memory_used = cpu_metrics.get("memory_used", 0)

    print(f"   - Execution Time: {exec_time:.4f}s")
    print(f"   - Memory Used: {memory_used:.2f}MB")
    print(f"   - Points per Second: {5000 / max(exec_time, 0.001):.0f}")

    # Parameter sweep test
    print("\nðŸ”„ Running Parallel Parameter Sweep...")
    param_ranges = {"eta": [0.1, 0.3, 0.5], "sigma": [0.05, 0.1, 0.15], "alpha1": [0.1, 0.2, 0.3]}

    results, sweep_metrics = system.parallel_parameter_sweep(param_ranges, 1000)

    print(f"âœ… Parameter Sweep Complete!")
    print(f"   - Combinations Tested: {len(results)}")
    sweep_time = sweep_metrics.get("execution_time", 0)
    print(f"   - Sweep Time: {sweep_time:.4f}s")

    # Performance summary
    summary = system.get_performance_summary()
    print(f"\nðŸ“ˆ Performance Summary:")
    print(f"   - CPU Usage: {summary['system_info']['cpu_percent']:.1f}%")
    print(f"   - Memory Usage: {summary['system_info']['memory_percent']:.1f}%")
    print(f"   - Available Memory: {summary['system_info']['memory_available']:.1f}GB")

    return system, results, summary


if __name__ == "__main__":
    system, results, summary = run_optimization_demo()
