import numpy as np
import matplotlib.pyplot as plt
import time
import psutil
import gc
import tracemalloc
import cProfile
import pstats
from io import StringIO
from scipy.integrate import solve_ivp
import seaborn as sns
from typing import Dict, List, Tuple, Any
import warnings

warnings.filterwarnings("ignore")


class HamiltonianBenchmarkSuite:
    """
    Comprehensive benchmarking suite for Hamiltonian analysis systems.

    Features:
    - Performance profiling (CPU, memory, I/O)
    - Computational complexity analysis
    - Optimization recommendations
    - Scalability testing
    - Memory leak detection
    - Algorithm efficiency comparison
    """

    def __init__(self):
        self.benchmark_results = {}
        self.performance_metrics = {}
        self.memory_usage = {}
        self.complexity_analysis = {}

    def softplus(self, x):
        return np.log(1 + np.exp(x))

    def sigmoid(self, x):
        return 1 / (1 + np.exp(-x))

    def benchmark_hamiltonian_system(self, t_span=(0, 10), n_points=1000, params=None):
        """Benchmark the core Hamiltonian system computation."""
        print("üöÄ Benchmarking Hamiltonian System Performance")
        print("=" * 50)

        if params is None:
            params = [0.3, 0.1, 0.2, 0.5, 0.5, 0.1]

        def hamiltonian_system(t, state, params):
            H, dH_dt = state
            eta, sigma, alpha1, tau, gamma, delta = params

            # Oscillatory terms
            A1 = 1.0 + 0.1 * np.sin(0.5 * t)
            A2 = 0.8 + 0.2 * np.cos(0.3 * t)
            A3 = 1.2 + 0.15 * np.sin(0.7 * t)

            B1 = 2.0 + 0.1 * t
            B2 = 1.5 + 0.05 * t
            B3 = 2.5 + 0.15 * t

            oscillatory = (
                A1 * np.sin(B1 * t)
                + A2 * np.sin(B2 * t + np.pi / 3)
                + A3 * np.sin(B3 * t + np.pi / 6)
            )

            # Drift terms
            drift = 0.01 * t**2 + alpha1 * np.sin(2 * np.pi * t) + 0.05 * np.log(1 + t)

            # Delayed feedback
            delayed_feedback = eta * H * self.sigmoid(gamma * H)

            # Stochastic term
            noise = np.random.normal(0, sigma * (1 + 0.2 * abs(H)))

            # External input
            external_input = delta * np.sin(3 * t) * np.exp(-0.2 * t)

            H_total = oscillatory + drift + delayed_feedback + noise + external_input

            return [dH_dt, H_total - H]

        # Memory tracking
        tracemalloc.start()
        process = psutil.Process()
        initial_memory = process.memory_info().rss / 1024 / 1024  # MB

        # CPU profiling
        profiler = cProfile.Profile()
        profiler.enable()

        # Timing
        start_time = time.time()

        # Run simulation
        t_eval = np.linspace(t_span[0], t_span[1], n_points)
        solution = solve_ivp(
            lambda t, state: hamiltonian_system(t, state, params),
            t_span,
            [0.0, 0.0],
            t_eval=t_eval,
            method="RK45",
            rtol=1e-8,
            atol=1e-10,
        )

        end_time = time.time()
        execution_time = end_time - start_time

        # Memory usage
        current, peak = tracemalloc.get_traced_memory()
        final_memory = process.memory_info().rss / 1024 / 1024  # MB
        memory_used = final_memory - initial_memory

        # CPU profiling results
        profiler.disable()
        s = StringIO()
        stats = pstats.Stats(profiler, stream=s).sort_stats("cumulative")
        stats.print_stats(10)  # Top 10 functions

        # Performance metrics
        performance_metrics = {
            "execution_time": execution_time,
            "memory_used_mb": memory_used,
            "peak_memory_mb": peak / 1024 / 1024,
            "points_per_second": n_points / execution_time,
            "memory_per_point": memory_used / n_points,
            "cpu_profile": s.getvalue(),
        }

        tracemalloc.stop()

        print(f"‚è±Ô∏è  Execution Time: {execution_time:.4f} seconds")
        print(f"üíæ Memory Used: {memory_used:.2f} MB")
        print(f"üìä Points per Second: {performance_metrics['points_per_second']:.0f}")
        print(f"üîç Memory per Point: {performance_metrics['memory_per_point']:.4f} MB")

        self.performance_metrics["hamiltonian_system"] = performance_metrics
        return performance_metrics

    def benchmark_complexity_scaling(self, max_points=5000, step=500):
        """Benchmark computational complexity scaling."""
        print("\nüìà Complexity Scaling Analysis")
        print("=" * 40)

        point_counts = list(range(step, max_points + 1, step))
        execution_times = []
        memory_usage = []

        for n_points in point_counts:
            print(f"Testing {n_points} points...")

            # Memory tracking
            process = psutil.Process()
            initial_memory = process.memory_info().rss / 1024 / 1024

            start_time = time.time()

            # Run simulation
            t_eval = np.linspace(0, 10, n_points)
            solution = solve_ivp(
                lambda t, state: self._simple_hamiltonian(t, state),
                (0, 10),
                [0.0, 0.0],
                t_eval=t_eval,
                method="RK45",
            )

            end_time = time.time()
            final_memory = process.memory_info().rss / 1024 / 1024

            execution_times.append(end_time - start_time)
            memory_usage.append(final_memory - initial_memory)

        # Complexity analysis
        point_counts_array = np.array(point_counts)
        execution_times_array = np.array(execution_times)

        # Fit different complexity models
        models = {
            "O(n)": point_counts_array,
            "O(n log n)": point_counts_array * np.log(point_counts_array),
            "O(n¬≤)": point_counts_array**2,
            "O(n¬≥)": point_counts_array**3,
        }

        best_fit = None
        best_r_squared = 0

        for model_name, model_data in models.items():
            # Normalize for comparison
            normalized_model = model_data / model_data[0]
            normalized_times = execution_times_array / execution_times_array[0]

            # Calculate R-squared
            correlation = np.corrcoef(normalized_model, normalized_times)[0, 1]
            r_squared = correlation**2

            if r_squared > best_r_squared:
                best_r_squared = r_squared
                best_fit = model_name

        complexity_analysis = {
            "point_counts": point_counts,
            "execution_times": execution_times,
            "memory_usage": memory_usage,
            "best_fit_complexity": best_fit,
            "r_squared": best_r_squared,
        }

        print(f"üéØ Best Fit Complexity: {best_fit}")
        print(f"üìä R-squared: {best_r_squared:.4f}")

        self.complexity_analysis = complexity_analysis
        return complexity_analysis

    def _simple_hamiltonian(self, t, state):
        """Simplified Hamiltonian for complexity testing."""
        H, dH_dt = state
        return [dH_dt, np.sin(t) + 0.1 * H]

    def benchmark_memory_efficiency(self, n_runs=5):
        """Benchmark memory efficiency and detect leaks."""
        print("\nüîç Memory Efficiency Analysis")
        print("=" * 40)

        memory_traces = []

        for i in range(n_runs):
            # Force garbage collection
            gc.collect()

            # Memory tracking
            process = psutil.Process()
            initial_memory = process.memory_info().rss / 1024 / 1024

            # Run simulation
            t_eval = np.linspace(0, 10, 1000)
            solution = solve_ivp(
                lambda t, state: self._simple_hamiltonian(t, state),
                (0, 10),
                [0.0, 0.0],
                t_eval=t_eval,
                method="RK45",
            )

            final_memory = process.memory_info().rss / 1024 / 1024
            memory_traces.append(final_memory - initial_memory)

            # Clear variables
            del solution
            gc.collect()

        # Memory leak detection
        memory_array = np.array(memory_traces)
        memory_trend = np.polyfit(range(len(memory_array)), memory_array, 1)[0]

        memory_analysis = {
            "memory_traces": memory_traces,
            "average_memory": np.mean(memory_traces),
            "memory_std": np.std(memory_traces),
            "memory_trend": memory_trend,
            "potential_leak": memory_trend > 0.1,  # MB per run
        }

        print(f"üíæ Average Memory Usage: {memory_analysis['average_memory']:.2f} MB")
        print(f"üìä Memory Standard Deviation: {memory_analysis['memory_std']:.2f} MB")
        print(f"üìà Memory Trend: {memory_analysis['memory_trend']:.4f} MB/run")

        if memory_analysis["potential_leak"]:
            print("‚ö†Ô∏è  Potential memory leak detected!")
        else:
            print("‚úÖ No significant memory leak detected")

        self.memory_usage = memory_analysis
        return memory_analysis

    def benchmark_algorithm_comparison(self):
        """Compare different numerical integration methods."""
        print("\n‚ö° Algorithm Comparison Benchmark")
        print("=" * 40)

        methods = ["RK45", "RK23", "DOP853", "Radau", "BDF", "LSODA"]
        comparison_results = {}

        for method in methods:
            print(f"Testing {method}...")

            start_time = time.time()

            try:
                solution = solve_ivp(
                    lambda t, state: self._complex_hamiltonian(t, state),
                    (0, 10),
                    [0.0, 0.0],
                    t_eval=np.linspace(0, 10, 1000),
                    method=method,
                    rtol=1e-8,
                    atol=1e-10,
                )

                end_time = time.time()
                execution_time = end_time - start_time

                # Calculate accuracy (using RK45 as reference)
                if method == "RK45":
                    reference_solution = solution
                    accuracy = 1.0
                else:
                    # Compare with reference
                    max_diff = np.max(np.abs(solution.y - reference_solution.y))
                    accuracy = 1.0 / (1.0 + max_diff)

                comparison_results[method] = {
                    "execution_time": execution_time,
                    "accuracy": accuracy,
                    "success": True,
                }

            except Exception as e:
                comparison_results[method] = {
                    "execution_time": float("inf"),
                    "accuracy": 0.0,
                    "success": False,
                    "error": str(e),
                }

        # Find best method
        successful_methods = {k: v for k, v in comparison_results.items() if v["success"]}

        if successful_methods:
            best_method = min(successful_methods.items(), key=lambda x: x[1]["execution_time"])

            print(f"üèÜ Best Method: {best_method[0]}")
            print(f"‚è±Ô∏è  Execution Time: {best_method[1]['execution_time']:.4f}s")
            print(f"üéØ Accuracy: {best_method[1]['accuracy']:.4f}")

        self.benchmark_results["algorithm_comparison"] = comparison_results
        return comparison_results

    def _complex_hamiltonian(self, t, state):
        """Complex Hamiltonian for algorithm comparison."""
        H, dH_dt = state

        # More complex system
        oscillatory = np.sin(2 * t) + 0.5 * np.sin(3 * t)
        drift = 0.01 * t**2 + 0.1 * np.sin(2 * np.pi * t)
        feedback = 0.3 * H * self.sigmoid(0.5 * H)
        noise = 0.1 * np.random.normal(0, 1)
        external = 0.1 * np.sin(3 * t) * np.exp(-0.2 * t)

        H_total = oscillatory + drift + feedback + noise + external

        return [dH_dt, H_total - H]

    def generate_benchmark_report(self):
        """Generate comprehensive benchmark report."""
        print("\nüìä Generating Benchmark Report...")

        report = f"""
# üèÜ Hamiltonian System Benchmark Report

## Performance Metrics

### Core System Performance
- Execution Time: {self.performance_metrics.get('hamiltonian_system', {}).get('execution_time', 'N/A'):.4f} seconds
- Memory Usage: {self.performance_metrics.get('hamiltonian_system', {}).get('memory_used_mb', 'N/A'):.2f} MB
- Points per Second: {self.performance_metrics.get('hamiltonian_system', {}).get('points_per_second', 'N/A'):.0f}
- Memory per Point: {self.performance_metrics.get('hamiltonian_system', {}).get('memory_per_point', 'N/A'):.4f} MB

### Complexity Analysis
- Best Fit Complexity: {self.complexity_analysis.get('best_fit_complexity', 'N/A')}
- R-squared: {self.complexity_analysis.get('r_squared', 'N/A'):.4f}

### Memory Efficiency
- Average Memory Usage: {self.memory_usage.get('average_memory', 'N/A'):.2f} MB
- Memory Standard Deviation: {self.memory_usage.get('memory_std', 'N/A'):.2f} MB
- Memory Trend: {self.memory_usage.get('memory_trend', 'N/A'):.4f} MB/run
- Memory Leak Detected: {'Yes' if self.memory_usage.get('potential_leak', False) else 'No'}

### Algorithm Comparison
"""

        if "algorithm_comparison" in self.benchmark_results:
            for method, results in self.benchmark_results["algorithm_comparison"].items():
                if results["success"]:
                    report += f"- {method}: {results['execution_time']:.4f}s, Accuracy: {results['accuracy']:.4f}\n"
                else:
                    report += f"- {method}: Failed ({results.get('error', 'Unknown error')})\n"

        report += f"""
## Optimization Recommendations

### Performance Optimizations
1. **Algorithm Selection**: Use the fastest successful method for your specific problem
2. **Memory Management**: Implement proper cleanup for large-scale simulations
3. **Parallelization**: Consider parallel processing for parameter sweeps
4. **Caching**: Cache frequently computed values

### Scalability Considerations
1. **Complexity**: The system shows {self.complexity_analysis.get('best_fit_complexity', 'unknown')} scaling
2. **Memory**: Monitor memory usage for large-scale simulations
3. **Accuracy**: Balance speed vs. accuracy based on requirements

## System Requirements
- Minimum RAM: {max(self.memory_usage.get('average_memory', 0) * 2, 512):.0f} MB
- Recommended RAM: {max(self.memory_usage.get('average_memory', 0) * 4, 1024):.0f} MB
- CPU: Multi-core recommended for parallel processing

---
*Generated by Hamiltonian Benchmark Suite*
"""

        with open("hamiltonian_benchmark_report.md", "w") as f:
            f.write(report)

        print("üìÑ Benchmark report saved as 'hamiltonian_benchmark_report.md'")
        return report

    def create_benchmark_visualizations(self):
        """Create comprehensive benchmark visualizations."""
        print("\nüìà Creating Benchmark Visualizations...")

        fig, axes = plt.subplots(2, 3, figsize=(18, 12))

        # 1. Complexity scaling
        if self.complexity_analysis:
            ax1 = axes[0, 0]
            ax1.plot(
                self.complexity_analysis["point_counts"],
                self.complexity_analysis["execution_times"],
                "bo-",
            )
            ax1.set_xlabel("Number of Points")
            ax1.set_ylabel("Execution Time (s)")
            ax1.set_title("Complexity Scaling")
            ax1.grid(True, alpha=0.3)

        # 2. Memory usage over time
        if self.memory_usage:
            ax2 = axes[0, 1]
            ax2.plot(self.memory_usage["memory_traces"], "ro-")
            ax2.set_xlabel("Run Number")
            ax2.set_ylabel("Memory Usage (MB)")
            ax2.set_title("Memory Efficiency")
            ax2.grid(True, alpha=0.3)

        # 3. Algorithm comparison
        if "algorithm_comparison" in self.benchmark_results:
            ax3 = axes[0, 2]
            methods = []
            times = []
            for method, results in self.benchmark_results["algorithm_comparison"].items():
                if results["success"]:
                    methods.append(method)
                    times.append(results["execution_time"])

            if methods:
                bars = ax3.bar(methods, times)
                ax3.set_ylabel("Execution Time (s)")
                ax3.set_title("Algorithm Performance")
                ax3.tick_params(axis="x", rotation=45)

        # 4. Performance metrics
        if self.performance_metrics.get("hamiltonian_system"):
            ax4 = axes[1, 0]
            metrics = self.performance_metrics["hamiltonian_system"]
            labels = ["Time (s)", "Memory (MB)", "Points/s"]
            values = [
                metrics["execution_time"],
                metrics["memory_used_mb"],
                metrics["points_per_second"] / 1000,
            ]  # Scale for visualization

            bars = ax4.bar(labels, values)
            ax4.set_title("Performance Metrics")
            ax4.tick_params(axis="x", rotation=45)

        # 5. Memory trend analysis
        if self.memory_usage:
            ax5 = axes[1, 1]
            x = np.arange(len(self.memory_usage["memory_traces"]))
            ax5.scatter(x, self.memory_usage["memory_traces"], alpha=0.6)

            # Trend line
            z = np.polyfit(x, self.memory_usage["memory_traces"], 1)
            p = np.poly1d(z)
            ax5.plot(x, p(x), "r--", alpha=0.8)

            ax5.set_xlabel("Run Number")
            ax5.set_ylabel("Memory Usage (MB)")
            ax5.set_title("Memory Trend Analysis")
            ax5.grid(True, alpha=0.3)

        # 6. Summary statistics
        ax6 = axes[1, 2]
        ax6.axis("off")

        summary_text = f"""
Benchmark Summary

Performance:
‚Ä¢ Execution Time: {self.performance_metrics.get('hamiltonian_system', {}).get('execution_time', 'N/A'):.4f}s
‚Ä¢ Memory Usage: {self.performance_metrics.get('hamiltonian_system', {}).get('memory_used_mb', 'N/A'):.2f}MB
‚Ä¢ Points/sec: {self.performance_metrics.get('hamiltonian_system', {}).get('points_per_second', 'N/A'):.0f}

Complexity:
‚Ä¢ Best Fit: {self.complexity_analysis.get('best_fit_complexity', 'N/A')}
‚Ä¢ R¬≤: {self.complexity_analysis.get('r_squared', 'N/A'):.4f}

Memory:
‚Ä¢ Average: {self.memory_usage.get('average_memory', 'N/A'):.2f}MB
‚Ä¢ Leak: {'Yes' if self.memory_usage.get('potential_leak', False) else 'No'}
        """

        ax6.text(
            0.1,
            0.9,
            summary_text,
            transform=ax6.transAxes,
            fontsize=10,
            verticalalignment="top",
            bbox=dict(boxstyle="round", facecolor="lightblue", alpha=0.8),
        )

        plt.tight_layout()
        plt.savefig("hamiltonian_benchmark_visualizations.png", dpi=300, bbox_inches="tight")
        plt.show()

        print("üìä Benchmark visualizations saved as 'hamiltonian_benchmark_visualizations.png'")


def run_comprehensive_benchmark():
    """Run the complete benchmark suite."""
    print("üèÜ Comprehensive Hamiltonian Benchmark Suite")
    print("=" * 60)

    benchmark = HamiltonianBenchmarkSuite()

    # 1. Core system performance
    performance = benchmark.benchmark_hamiltonian_system()

    # 2. Complexity scaling
    complexity = benchmark.benchmark_complexity_scaling()

    # 3. Memory efficiency
    memory = benchmark.benchmark_memory_efficiency()

    # 4. Algorithm comparison
    algorithms = benchmark.benchmark_algorithm_comparison()

    # 5. Generate report
    report = benchmark.generate_benchmark_report()

    # 6. Create visualizations
    benchmark.create_benchmark_visualizations()

    print("\nüèÜ Benchmark Suite Complete!")
    print("Files generated:")
    print("  - hamiltonian_benchmark_report.md")
    print("  - hamiltonian_benchmark_visualizations.png")

    return benchmark


if __name__ == "__main__":
    # Run the comprehensive benchmark
    benchmark = run_comprehensive_benchmark()
